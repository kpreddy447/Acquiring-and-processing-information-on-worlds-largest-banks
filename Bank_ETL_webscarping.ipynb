{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f85d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbca997",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54c03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "csv_path = '/home/project/Countries_by_GDP.csv'\n",
    "df = pd.DataFrame(columns=[\"Name\",\"MC_USD_Billion\"])\n",
    "count = 0\n",
    "log_file=\"code_log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f134cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for ETL operations on Country-GDP data\n",
    "\n",
    "# Importing the required libraries\n",
    "\n",
    "def log_progress(log_file,log_text):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(log_file, \"a\") as log_file:\n",
    "        log_file.write(f\"{timestamp} : {log_text}\\n\")\n",
    "\n",
    "def extract(url, df):\n",
    "    ''' This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. '''\n",
    "    html_page = requests.get(url).text\n",
    "    data = BeautifulSoup(html_page, 'html.parser')\n",
    "    banks_data = data.find_all('tbody')\n",
    "    rows=banks_data[0].find_all('tr')\n",
    "    for row in rows:\n",
    "        col = row.find_all('td')\n",
    "        if len(col)>2:\n",
    "            dict_data = {\n",
    "                \"Name\" : col[1].text.strip(),\n",
    "                \"MC_USD_Billion\" : col[2].text.strip()\n",
    "            }\n",
    "            df1 = pd.DataFrame(dict_data, index=[0])\n",
    "            df = pd.concat([df,df1],ignore_index=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def transform(data_f, csv_path):\n",
    "    ''' This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies'''\n",
    "#     print(data_f,\"data\")\n",
    "    fr_d = pd.read_csv(csv_path)\n",
    "#     print(fr_d,\"cvs read\")\n",
    "    rate_dict = dict(zip(fr_d[\"Currency\"], fr_d[\"Rate\"]))\n",
    "#     print(rate_dict,\"dict\")\n",
    "    data_f['MC_GBP_Billion'] = [np.round(float(x)*rate_dict['GBP'],2) for x in data_f['MC_USD_Billion']]\n",
    "    data_f[\"MC_INR_Billion\"] = [np.round(float(x)*rate_dict['INR'],2) for x in data_f['MC_USD_Billion']]\n",
    "    data_f[\"MC_EUR_Billion\"] = [np.round(float(x)*rate_dict['EUR'],2) for x in data_f['MC_USD_Billion']]\n",
    "\n",
    "    return data_f\n",
    "\n",
    "def load_to_csv(df, output_path):\n",
    "    ''' This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.'''\n",
    "    data_f.to_csv(\"Largest_banks_data.csv\")\n",
    "\n",
    "def load_to_db(df, connection, table_name):\n",
    "    ''' This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.'''\n",
    "    df.to_sql(table_name,connection,if_exists='replace', index=False)  # Use 'replace' to overwrite the table if it already exists\n",
    "    cursor = connection.cursor()\n",
    "#     cursor.execute(\"Select * from Largest_banks\")\n",
    "#     rows = cursor.fetchall()\n",
    "#     print(rows)\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    ''' This function runs the query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. '''\n",
    "    cursor=sql_connection.cursor()\n",
    "    cursor.execute(query_statement)\n",
    "    rows = cursor.fetchall()\n",
    "    print(rows)\n",
    "\n",
    "    ''' Here, you define the required entities and call the relevant\n",
    "    functions in the correct order to complete the project. Note that this\n",
    "    portion is not inside any function.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb9fd82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data extracted\n",
      "                                       Name MC_USD_Billion\n",
      "0                           JPMorgan Chase         432.92\n",
      "1                          Bank of America         231.52\n",
      "2  Industrial and Commercial Bank of China         194.56\n",
      "3               Agricultural Bank of China         160.68\n",
      "4                                HDFC Bank         157.91\n",
      "5                              Wells Fargo         155.87\n",
      "6                        HSBC Holdings PLC         148.90\n",
      "7                           Morgan Stanley         140.83\n",
      "8                  China Construction Bank         139.82\n",
      "9                            Bank of China         136.81\n",
      "                                      Name MC_USD_Billion\n",
      "0                           JPMorgan Chase         432.92\n",
      "1                          Bank of America         231.52\n",
      "2  Industrial and Commercial Bank of China         194.56\n",
      "3               Agricultural Bank of China         160.68\n",
      "4                                HDFC Bank         157.91\n",
      "5                              Wells Fargo         155.87\n",
      "6                        HSBC Holdings PLC         148.90\n",
      "7                           Morgan Stanley         140.83\n",
      "8                  China Construction Bank         139.82\n",
      "9                            Bank of China         136.81 data\n",
      "  Currency   Rate\n",
      "0      EUR   0.93\n",
      "1      GBP   0.80\n",
      "2      INR  82.95 cvs read\n",
      "{'EUR': 0.93, 'GBP': 0.8, 'INR': 82.95} dict\n",
      "data transformed\n",
      "                                       Name MC_USD_Billion  MC_GBP_Billion  \\\n",
      "0                           JPMorgan Chase         432.92          346.34   \n",
      "1                          Bank of America         231.52          185.22   \n",
      "2  Industrial and Commercial Bank of China         194.56          155.65   \n",
      "3               Agricultural Bank of China         160.68          128.54   \n",
      "4                                HDFC Bank         157.91          126.33   \n",
      "5                              Wells Fargo         155.87          124.70   \n",
      "6                        HSBC Holdings PLC         148.90          119.12   \n",
      "7                           Morgan Stanley         140.83          112.66   \n",
      "8                  China Construction Bank         139.82          111.86   \n",
      "9                            Bank of China         136.81          109.45   \n",
      "\n",
      "   MC_INR_Billion  MC_EUR_Billion  \n",
      "0        35910.71          402.62  \n",
      "1        19204.58          215.31  \n",
      "2        16138.75          180.94  \n",
      "3        13328.41          149.43  \n",
      "4        13098.63          146.86  \n",
      "5        12929.42          144.96  \n",
      "6        12351.26          138.48  \n",
      "7        11681.85          130.97  \n",
      "8        11598.07          130.03  \n",
      "9        11348.39          127.23  \n",
      "[('JPMorgan Chase', '432.92', 346.34, 35910.71, 402.62), ('Bank of America', '231.52', 185.22, 19204.58, 215.31), ('Industrial and Commercial Bank of China', '194.56', 155.65, 16138.75, 180.94), ('Agricultural Bank of China', '160.68', 128.54, 13328.41, 149.43), ('HDFC Bank', '157.91', 126.33, 13098.63, 146.86), ('Wells Fargo', '155.87', 124.7, 12929.42, 144.96), ('HSBC Holdings PLC', '148.90', 119.12, 12351.26, 138.48), ('Morgan Stanley', '140.83', 112.66, 11681.85, 130.97), ('China Construction Bank', '139.82', 111.86, 11598.07, 130.03), ('Bank of China', '136.81', 109.45, 11348.39, 127.23)]\n",
      "[('JPMorgan Chase', '432.92', 346.34, 35910.71, 402.62), ('Bank of America', '231.52', 185.22, 19204.58, 215.31), ('Industrial and Commercial Bank of China', '194.56', 155.65, 16138.75, 180.94), ('Agricultural Bank of China', '160.68', 128.54, 13328.41, 149.43), ('HDFC Bank', '157.91', 126.33, 13098.63, 146.86), ('Wells Fargo', '155.87', 124.7, 12929.42, 144.96), ('HSBC Holdings PLC', '148.90', 119.12, 12351.26, 138.48), ('Morgan Stanley', '140.83', 112.66, 11681.85, 130.97), ('China Construction Bank', '139.82', 111.86, 11598.07, 130.03), ('Bank of China', '136.81', 109.45, 11348.39, 127.23)]\n"
     ]
    }
   ],
   "source": [
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "csv_path = '/home/project/Countries_by_GDP.csv'\n",
    "df = pd.DataFrame(columns=[\"Name\",\"MC_USD_Billion\"])\n",
    "count = 0\n",
    "log_file=\"code_log.txt\"\n",
    "\n",
    "log_progress(log_file,\"Preliminaries complete. Initiating ETL process\")\n",
    "\n",
    "data_f = extract(url,df)\n",
    "log_progress(log_file,\"Data extraction complete. Initiating Transformation process\")\n",
    "print(\"data extracted\\n\",data_f)\n",
    "\n",
    "u = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\"\n",
    "df_trans = transform(data_f,u)\n",
    "print(\"data transformed\\n\",df_trans)\n",
    "log_progress(log_file,\"Data transformation complete. Initiating Loading process\")\n",
    "\n",
    "path = \"./Largest_banks_data.csv\"\n",
    "load_to_csv(df_trans,path)\n",
    "log_progress(log_file,\"Data saved to CSV file\")\n",
    "\n",
    "log_progress(log_file,\"SQL Connection initiated\")\n",
    "connection = sqlite3.connect('Banks.db')\n",
    "load_to_db(df_trans,connection,table_name)\n",
    "log_progress(log_file,\"Process Complete\")\n",
    "\n",
    "run_query(\"SELECT * FROM Largest_banks\", connection)\n",
    "connection.close()\n",
    "log_progress(log_file,\"Server Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a704c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c608e40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-11 15:05:09 : Initiated web scraping\n",
      "2025-03-11 15:26:59 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 15:27:02 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 15:27:02 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 15:27:02 : Data saved to CSV file\n",
      "2025-03-11 15:27:02 : SQL Connection initiated\n",
      "2025-03-11 15:27:02 : Process Complete\n",
      "2025-03-11 15:27:02 : Server Connection closed\n",
      "2025-03-11 16:00:05 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:00:06 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:00:07 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:00:07 : Data saved to CSV file\n",
      "2025-03-11 16:00:07 : SQL Connection initiated\n",
      "2025-03-11 16:00:32 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:00:34 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:00:34 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:00:34 : Data saved to CSV file\n",
      "2025-03-11 16:00:34 : SQL Connection initiated\n",
      "2025-03-11 16:00:35 : Process Complete\n",
      "2025-03-11 16:01:08 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:01:10 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:01:10 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:01:10 : Data saved to CSV file\n",
      "2025-03-11 16:01:10 : SQL Connection initiated\n",
      "2025-03-11 16:01:10 : Process Complete\n",
      "2025-03-11 16:01:24 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:01:26 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:01:27 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:01:27 : Data saved to CSV file\n",
      "2025-03-11 16:01:27 : SQL Connection initiated\n",
      "2025-03-11 16:01:27 : Process Complete\n",
      "2025-03-11 16:01:27 : Server Connection closed\n",
      "2025-03-11 16:34:04 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:34:05 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:34:06 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:34:06 : Data saved to CSV file\n",
      "2025-03-11 16:34:06 : SQL Connection initiated\n",
      "2025-03-11 16:34:06 : Process Complete\n",
      "2025-03-11 16:34:06 : Server Connection closed\n",
      "2025-03-11 16:34:30 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:34:32 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:34:32 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:34:32 : Data saved to CSV file\n",
      "2025-03-11 16:34:32 : SQL Connection initiated\n",
      "2025-03-11 16:34:33 : Process Complete\n",
      "2025-03-11 16:34:33 : Server Connection closed\n",
      "2025-03-11 16:34:53 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:34:55 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:34:55 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:34:55 : Data saved to CSV file\n",
      "2025-03-11 16:34:55 : SQL Connection initiated\n",
      "2025-03-11 16:34:55 : Process Complete\n",
      "2025-03-11 16:34:55 : Server Connection closed\n",
      "2025-03-11 16:35:31 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:35:33 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:35:33 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:35:33 : Data saved to CSV file\n",
      "2025-03-11 16:35:33 : SQL Connection initiated\n",
      "2025-03-11 16:35:33 : Process Complete\n",
      "2025-03-11 16:35:33 : Server Connection closed\n",
      "2025-03-11 16:36:57 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:36:59 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:36:59 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:36:59 : Data saved to CSV file\n",
      "2025-03-11 16:36:59 : SQL Connection initiated\n",
      "2025-03-11 16:36:59 : Process Complete\n",
      "2025-03-11 16:36:59 : Server Connection closed\n",
      "2025-03-11 16:38:46 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:38:48 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:38:48 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:38:48 : Data saved to CSV file\n",
      "2025-03-11 16:38:48 : SQL Connection initiated\n",
      "2025-03-11 16:38:48 : Process Complete\n",
      "2025-03-11 16:38:48 : Server Connection closed\n",
      "2025-03-11 16:39:51 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:39:53 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:39:54 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:39:54 : Data saved to CSV file\n",
      "2025-03-11 16:39:54 : SQL Connection initiated\n",
      "2025-03-11 16:39:54 : Process Complete\n",
      "2025-03-11 16:39:54 : Server Connection closed\n",
      "2025-03-11 16:40:29 : Preliminaries complete. Initiating ETL process\n",
      "2025-03-11 16:40:31 : Data extraction complete. Initiating Transformation process\n",
      "2025-03-11 16:40:32 : Data transformation complete. Initiating Loading process\n",
      "2025-03-11 16:40:32 : Data saved to CSV file\n",
      "2025-03-11 16:40:32 : SQL Connection initiated\n",
      "2025-03-11 16:40:32 : Process Complete\n",
      "2025-03-11 16:40:32 : Server Connection closed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(log_file, \"r\") as log_file:\n",
    "        text=log_file.read()\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef5523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
